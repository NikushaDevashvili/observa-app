# Cookbook: Anthropic Integration

Step-by-step guide to integrating Observa with Anthropic's Claude API.

## Prerequisites

- Node.js 16+ or any JavaScript runtime
- Anthropic API key
- Observa API key (get from [Settings](https://observa-app.vercel.app/dashboard/settings))

## Set Up Environment

Install dependencies and set up environment variables:

```bash
npm install observa-sdk @anthropic-ai/sdk
```

```javascript
// .env
ANTHROPIC_API_KEY=sk-ant-***
OBSERVA_API_KEY=your-observa-api-key
OBSERVA_API_URL=https://observa-api.vercel.app
```

## Example 1: Basic Message Completion (Auto-Capture - Recommended)

Use `observeAnthropic()` for automatic tracking - the easiest way:

```javascript
import { init } from 'observa-sdk';
import Anthropic from '@anthropic-ai/sdk';

// Initialize Observa SDK
const observa = init({
  apiKey: process.env.OBSERVA_API_KEY,
  apiUrl: process.env.OBSERVA_API_URL,
});

// Initialize Anthropic client
const anthropic = new Anthropic({
  apiKey: process.env.ANTHROPIC_API_KEY,
});

// Wrap with Observa - automatic tracking!
const wrappedAnthropic = observa.observeAnthropic(anthropic, {
  name: 'my-app',
  userId: 'user-123',
});

// Use wrapped client - automatically tracked!
const response = await wrappedAnthropic.messages.create({
  model: 'claude-3-opus-20240229',
  max_tokens: 1024,
  messages: [
    { role: 'user', content: 'What is the capital of France?' }
  ],
});

console.log(response.content[0].text);
```

## Example 2: Streaming (Auto-Capture)

Streaming works automatically with `observeAnthropic()` - no extra code needed!

```javascript
// Wrap client once (same as Example 1)
const wrappedAnthropic = observa.observeAnthropic(anthropic, {
  name: 'my-app',
});

// Streaming automatically tracked!
const stream = await wrappedAnthropic.messages.create({
  model: 'claude-3-opus-20240229',
  max_tokens: 1024,
  messages: [
    { role: 'user', content: 'Explain quantum computing' }
  ],
  stream: true,
});

for await (const chunk of stream) {
  if (chunk.type === 'content_block_delta' && chunk.delta.type === 'text_delta') {
    const text = chunk.delta.text;
    process.stdout.write(text);
  }
}
```

## Example 3: Multi-Turn Conversation

Track conversations with automatic capture:

```javascript
const wrappedAnthropic = observa.observeAnthropic(anthropic, {
  name: 'chat-app',
  userId: 'user-123',
});

const conversationHistory = [];

async function sendMessage(message) {
  conversationHistory.push({ role: 'user', content: message });
  
  // Use wrapped client - automatically tracked!
  const response = await wrappedAnthropic.messages.create({
    model: 'claude-3-opus-20240229',
    max_tokens: 1024,
    messages: conversationHistory,
  });
  
  const assistantMessage = response.content[0].text;
  conversationHistory.push({ role: 'assistant', content: assistantMessage });
  
  return assistantMessage;
}

// First message
const response1 = await sendMessage("Hello, my name is Alice");
console.log(response1);

// Follow-up message
const response2 = await sendMessage("What's my name?");
console.log(response2);
```

## Example 4: With System Prompt

System prompts work automatically:

```javascript
const wrappedAnthropic = observa.observeAnthropic(anthropic, {
  name: 'poetry-app',
});

// Use wrapped client - automatically tracked!
const response = await wrappedAnthropic.messages.create({
  model: 'claude-3-opus-20240229',
  max_tokens: 1024,
  system: "You are a helpful assistant that writes poetry.",
  messages: [
    { role: 'user', content: 'Write a haiku about programming' }
  ],
});

console.log(response.content[0].text);
```

## Example 5: Tool Use (Function Calling)

Tool use is automatically tracked:

```javascript
const tools = [
  {
    name: "get_weather",
    description: "Get the current weather in a location",
    input_schema: {
      type: "object",
      properties: {
        location: {
          type: "string",
          description: "The city and state, e.g. San Francisco, CA",
        },
      },
      required: ["location"],
    },
  },
];

async function getWeather(location) {
  if (location === "Berlin, Germany") {
    return "20Â°C, sunny";
  }
  return "Weather unknown";
}

const wrappedAnthropic = observa.observeAnthropic(anthropic, {
  name: 'tool-app',
});

// Use wrapped client - automatically tracked!
const response = await wrappedAnthropic.messages.create({
  model: 'claude-3-opus-20240229',
  max_tokens: 1024,
  tools: tools,
  messages: [
    { role: 'user', content: "What's the weather in Berlin?" }
  ],
});

// Handle tool use
if (response.stop_reason === 'tool_use') {
  const toolUse = response.content.find(item => item.type === 'tool_use');
  if (toolUse && toolUse.name === 'get_weather') {
    const location = toolUse.input.location;
    const weather = await getWeather(location);
    console.log(weather);
  }
}
```

## PII Redaction

Use the `redact` option to sanitize sensitive data:

```javascript
const wrappedAnthropic = observa.observeAnthropic(anthropic, {
  name: 'secure-app',
  redact: (data) => {
    // Remove sensitive data before sending to Observa
    if (data?.messages) {
      return {
        ...data,
        messages: data.messages.map(msg => ({
          ...msg,
          content: '[REDACTED]'
        }))
      };
    }
    return data;
  },
});
```

## Best Practices

1. **Use Auto-Capture**: `observeAnthropic()` is the recommended approach - it automatically captures 90%+ of your LLM interactions
2. **Wrap Once**: Wrap your Anthropic client once and reuse it throughout your application
3. **Streaming Support**: Streaming works automatically - no extra code needed
4. **PII Redaction**: Use the `redact` option to sanitize sensitive data before sending to Observa
5. **Error Handling**: Wrap LLM calls in try-catch blocks

## View Your Traces

After running these examples:

1. Go to [Dashboard](https://observa-app.vercel.app/dashboard)
2. Navigate to **Traces**
3. Filter by model to see Claude calls
4. Click on a trace for detailed information

## Next Steps

- **[OpenAI Integration](./openai-integration)**: Compare with OpenAI examples
- **[Multi-Turn Conversations](./multi-turn-conversations)**: Advanced conversation patterns
- **[Function Calling](./function-calling)**: Tool usage examples
- **[SDK Reference](../sdk/initialization)**: Complete API documentation
